{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def pre_processing(image_list):\n",
    "    images=list()\n",
    "    limit=len(image_list)\n",
    "    #print(limit)\n",
    "    seq=[]\n",
    "    i=0\n",
    "    while (i<limit):\n",
    "        seq_lim=i+15\n",
    "        if seq_lim<=limit:\n",
    "            for j in range(i,seq_lim):\n",
    "                seq.append(image_list[j])\n",
    "            images.append(seq)\n",
    "            seq=[]\n",
    "        i=i+5\n",
    "    return images      \n",
    "def load_image(path):\n",
    "    image_list=list()\n",
    "    for filename in os.listdir(path):\n",
    "        img=cv2.imread(os.path.join(path,filename))\n",
    "        img=cv2.resize(img,(100,100))\n",
    "        image_list.append(img)\n",
    "    return (pre_processing(image_list))\n",
    "def read_directory(dirname):\n",
    "    violent_list=list()\n",
    "    non_violent_list=list()\n",
    "    VC=0\n",
    "    while VC<500:\n",
    "        path1=dirname+\"\\\\Violent\\\\\"+str(VC)\n",
    "        image_list1=load_image(path1)\n",
    "        for img_seq in image_list1:\n",
    "            violent_list.append(img_seq)\n",
    "        path2=dirname+\"\\\\Nonviolent\\\\\"+str(VC)\n",
    "        image_list2=load_image(path2)\n",
    "        for img_seq in image_list2:\n",
    "            non_violent_list.append(img_seq)\n",
    "        VC=VC+1\n",
    "    return(violent_list,non_violent_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violent_list,non_violent_list=read_directory(\"Z:\\\\dataset\\\\DWT-3\")\n",
    "print(len(violent_list))\n",
    "print(len(non_violent_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=list()\n",
    "train_data=list()\n",
    "for seq in violent_list[:2706]:\n",
    "    train_data.append([seq,1])\n",
    "for seq in violent_list[2706:]:\n",
    "    test_data.append([seq,1])\n",
    "    \n",
    "for seq in non_violent_list[:2700]:\n",
    "    train_data.append([seq,0])\n",
    "for seq in non_violent_list[2700:]:\n",
    "    test_data.append([seq,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(train_data)\n",
    "for samples in train_data[:10]:\n",
    "    print(samples[1])\n",
    "x=[]\n",
    "y=[]\n",
    "for img,lab in train_data:\n",
    "    x.append(img)\n",
    "    y.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(test_data)\n",
    "for samples in test_data[:10]:\n",
    "    print(samples[1])\n",
    "x_valid=[]\n",
    "y_valid=[]\n",
    "for img,lab in test_data:\n",
    "    x_valid.append(img)\n",
    "    y_valid.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving everything as pickle\n",
    "import pickle\n",
    "pickle_out=open(\"x.pickle\",\"wb\")\n",
    "pickle.dump(x,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "\n",
    "pickle_out=open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving everything as pickle\n",
    "import pickle\n",
    "pickle_out=open(\"x_valid.pickle\",\"wb\")\n",
    "pickle.dump(x_valid,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "\n",
    "pickle_out=open(\"y_valid.pickle\",\"wb\")\n",
    "pickle.dump(y_valid,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x=np.array(x).reshape(-1,15,100,100,3)\n",
    "print(x.shape)\n",
    "x_valid=np.array(x_valid).reshape(-1,15,100,100,3)\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=\"DWT-3-seq-12-b-softmax(.25)Dropout\"\n",
    "tensorboard=TensorBoard(log_dir=\"logs/{}\".format(Name))\n",
    "#x=x/255\n",
    "#x_valid=x_valid/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed,Dropout, Activation, Flatten,Conv2D, MaxPooling2D,LSTM,Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "## training the CNN\n",
    "cnn = Sequential()\n",
    "#input\n",
    "cnn.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "#1st layer\n",
    "cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D((2, 2)))\n",
    "cnn.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D((2, 2)))\n",
    "cnn.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D((2, 2)))\n",
    "cnn.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D((2, 2)))\n",
    "cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D((2, 2)))\n",
    "cnn.add(Flatten())\n",
    "\n",
    "model=Sequential()\n",
    "model.add(TimeDistributed(cnn,input_shape=x.shape[1:]))\n",
    "model.add(Bidirectional(LSTM(units=64,return_sequences=False)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "adam=Adam(lr=0.0005,decay=1e-6)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=adam,metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(x,y,epochs=10,validation_data=(x_valid,y_valid),batch_size=6,callbacks=[tensorboard])\n",
    "model.save(\"dwt_modified_2\"+str(i)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"dwt_modified_ulti.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard --logdir=logs/ --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
